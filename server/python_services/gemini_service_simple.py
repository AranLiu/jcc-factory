# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆPython Gemini æœåŠ¡
é¿å…ç¼–ç å…¼å®¹æ€§é—®é¢˜ï¼Œæ”¯æŒä»£ç†é…ç½®
"""

import os
import time
import json
import sys
import urllib3
import google.generativeai as genai

# è®¾ç½®UTF-8ç¼–ç è¾“å‡ºï¼Œè§£å†³Windowsæ§åˆ¶å°æ˜¾ç¤ºé—®é¢˜
if sys.platform.startswith('win'):
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# é…ç½®ä»£ç†æ”¯æŒ
def setup_proxy():
    """é…ç½®ä»£ç†è®¾ç½®"""
    proxy_config = {}
    
    # è·å–ä»£ç†é…ç½®
    http_proxy = os.getenv('HTTP_PROXY') or os.getenv('http_proxy')
    https_proxy = os.getenv('HTTPS_PROXY') or os.getenv('https_proxy')
    socks_proxy = os.getenv('SOCKS_PROXY') or os.getenv('socks_proxy')
    
    if http_proxy or https_proxy or socks_proxy:
        print(f"ğŸ”— æ£€æµ‹åˆ°ä»£ç†é…ç½®:")
        if http_proxy:
            print(f"  HTTPä»£ç†: {http_proxy}")
            proxy_config['http'] = http_proxy
        if https_proxy:
            print(f"  HTTPSä»£ç†: {https_proxy}")
            proxy_config['https'] = https_proxy
        if socks_proxy:
            print(f"  SOCKSä»£ç†: {socks_proxy}")
            
        # è®¾ç½®urllib3ä»£ç†
        if http_proxy or https_proxy:
            urllib3.util.connection.create_connection = _create_connection_with_proxy
            
    return proxy_config

def _create_connection_with_proxy(address, timeout=None, source_address=None):
    """åˆ›å»ºæ”¯æŒä»£ç†çš„è¿æ¥"""
    # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦å®ç°æ›´å¤æ‚çš„ä»£ç†é€»è¾‘
    # å½“å‰ç‰ˆæœ¬ä¾èµ–ç³»ç»Ÿçº§ä»£ç†è®¾ç½®
    return urllib3.util.connection.create_connection(address, timeout, source_address)

class GeminiService:
    def __init__(self, api_key=None, debug=False):
        """åˆå§‹åŒ–GeminiæœåŠ¡"""
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')
        self.debug = debug
        
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
        
        # è®¾ç½®ä»£ç†
        self.proxy_config = setup_proxy()
        
        # é…ç½®APIå¯†é’¥
        try:
            genai.configure(api_key=self.api_key)
            if self.debug:
                print("âœ… Gemini APIé…ç½®æˆåŠŸ")
        except Exception as e:
            print(f"âŒ Gemini APIé…ç½®å¤±è´¥: {e}")
            raise
    
    def analyze_video(self, video_path, prompt, model="gemini-2.0-flash", temperature=0.7):
        """åˆ†æè§†é¢‘å†…å®¹"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(video_path):
                return {
                    'success': False,
                    'error': f'è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}'
                }
            
            if self.debug:
                print(f"ğŸ“¹ å¼€å§‹åˆ†æè§†é¢‘: {video_path}")
                print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model}")
                print(f"ğŸŒ¡ï¸  æ¸©åº¦å‚æ•°: {temperature}")
            
            # ä¸Šä¼ è§†é¢‘æ–‡ä»¶
            uploaded_file = genai.upload_file(video_path)
            
            if self.debug:
                print(f"â¬†ï¸  æ–‡ä»¶ä¸Šä¼ å®Œæˆï¼Œç­‰å¾…å¤„ç†...")
            
            # ç­‰å¾…æ–‡ä»¶å¤„ç†å®Œæˆ
            max_wait_time = 600  # 10åˆ†é’Ÿ
            wait_time = 0
            file_info = uploaded_file
            
            while file_info.state.name != "ACTIVE" and wait_time < max_wait_time:
                time.sleep(5)
                wait_time += 5
                file_info = genai.get_file(uploaded_file.name)
                
                if self.debug and wait_time % 30 == 0:
                    print(f"â³ ç­‰å¾…æ–‡ä»¶å¤„ç†ä¸­... çŠ¶æ€: {file_info.state.name}, å·²ç­‰å¾…: {wait_time}ç§’")
            
            if file_info.state.name != "ACTIVE":
                return {
                    'success': False,
                    'error': f'æ–‡ä»¶å¤„ç†è¶…æ—¶ï¼Œå½“å‰çŠ¶æ€: {file_info.state.name}'
                }
            
            if self.debug:
                print(f"âœ… æ–‡ä»¶å¤„ç†å®Œæˆï¼Œå¼€å§‹ç”Ÿæˆå†…å®¹...")
            
            # åˆ›å»ºæ¨¡å‹å¹¶ç”Ÿæˆå†…å®¹
            model_instance = genai.GenerativeModel(model)
            
            # ç”Ÿæˆå†…å®¹
            response = model_instance.generate_content(
                [uploaded_file, prompt],
                generation_config=genai.types.GenerationConfig(
                    temperature=temperature,
                    max_output_tokens=8192
                )
            )

            if self.debug:
                print(f"ğŸ‰ è§†é¢‘åˆ†æå®Œæˆ")

            return {
                'success': True,
                'text': response.text,
                'usage': {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}
            }
            
        except Exception as e:
            error_msg = str(e)
            if self.debug:
                print(f"âŒ è§†é¢‘åˆ†æå¤±è´¥: {error_msg}")
            
            return {
                'success': False,
                'error': error_msg
            }
    
    def generate_text(self, content, system_instruction=None, model="gemini-2.0-flash", temperature=0.7):
        """ç”Ÿæˆæ–‡æœ¬å†…å®¹"""
        try:
            if self.debug:
                print(f"ğŸ“ å¼€å§‹ç”Ÿæˆæ–‡æœ¬")
                print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model}")
                print(f"ğŸŒ¡ï¸  æ¸©åº¦å‚æ•°: {temperature}")
            
            # åˆ›å»ºæ¨¡å‹
            if system_instruction:
                model_instance = genai.GenerativeModel(
                    model_name=model,
                    system_instruction=system_instruction
                )
                if self.debug:
                    print(f"ğŸ“‹ ç³»ç»ŸæŒ‡ä»¤: {system_instruction[:100]}...")
            else:
                model_instance = genai.GenerativeModel(model)
            
            # ç”Ÿæˆå†…å®¹
            response = model_instance.generate_content(
                content,
                generation_config=genai.types.GenerationConfig(
                    temperature=temperature,
                    max_output_tokens=8192
                )
            )

            if self.debug:
                print(f"ğŸ‰ æ–‡æœ¬ç”Ÿæˆå®Œæˆ")

            return {
                'success': True,
                'text': response.text,
                'usage': {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}
            }
            
        except Exception as e:
            error_msg = str(e)
            if self.debug:
                print(f"âŒ æ–‡æœ¬ç”Ÿæˆå¤±è´¥: {error_msg}")
            
            return {
                'success': False,
                'error': error_msg
            }

def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    if len(sys.argv) < 2:
        return
    
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        return
    
    try:
        # å¯ç”¨è°ƒè¯•æ¨¡å¼
        debug_mode = os.getenv('GEMINI_DEBUG', 'false').lower() == 'true'
        service = GeminiService(api_key, debug=debug_mode)
        command = sys.argv[1]
        
        if command == "video":
            if len(sys.argv) < 3:
                return
            video_path = sys.argv[2]
            prompt = sys.argv[3] if len(sys.argv) > 3 else "Analyze this video"
            
            # è§£ææ¨¡å‹é…ç½®å‚æ•°ï¼ˆJSONæ ¼å¼ï¼‰
            model_config = {}
            if len(sys.argv) > 4 and sys.argv[4].startswith('{'):
                try:
                    model_config = json.loads(sys.argv[4])
                except json.JSONDecodeError:
                    pass
            
            model = model_config.get('model', 'gemini-1.5-flash')
            temperature = model_config.get('temperature', 0.7)
            result = service.analyze_video(video_path, prompt, model, temperature)
            
        elif command == "text":
            if len(sys.argv) < 3:
                return
            content = sys.argv[2]
            system_instruction = sys.argv[3] if len(sys.argv) > 3 else None
            
            # è§£ææ¨¡å‹é…ç½®å‚æ•°ï¼ˆJSONæ ¼å¼ï¼‰
            model_config = {}
            # æŸ¥æ‰¾JSONå‚æ•° - å¯èƒ½åœ¨ç¬¬4ä¸ªæˆ–ç¬¬5ä¸ªä½ç½®
            for i in range(3, len(sys.argv)):
                if sys.argv[i].startswith('{'):
                    try:
                        model_config = json.loads(sys.argv[i])
                        break
                    except json.JSONDecodeError:
                        continue
            
            model = model_config.get('model', 'gemini-1.5-flash')
            temperature = model_config.get('temperature', 0.7)
            result = service.generate_text(content, system_instruction, model, temperature)
            
        else:
            result = {'success': False, 'error': 'Unknown command'}
        
        # ç®€å•è¾“å‡ºï¼Œé¿å…ç¼–ç é—®é¢˜
        print(json.dumps(result, ensure_ascii=False))
        
    except Exception as e:
        error_result = {'success': False, 'error': str(e)}
        print(json.dumps(error_result, ensure_ascii=False))

if __name__ == "__main__":
    main() 