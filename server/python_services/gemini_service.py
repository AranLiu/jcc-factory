# -*- coding: utf-8 -*-
"""
Python Gemini æœåŠ¡
æä¾›è§†é¢‘åˆ†æå’Œæ–‡æœ¬ç”ŸæˆåŠŸèƒ½
"""

import os
import time
import json
import sys
import io
from google import genai
from google.genai import types

# è®¾ç½®ç¼–ç ç¯å¢ƒå˜é‡
os.environ['PYTHONIOENCODING'] = 'utf-8'
if sys.platform.startswith('win'):
    os.environ['PYTHONLEGACYWINDOWSSTDIO'] = '0'

# ç®€åŒ–çš„ç¼–ç å¤„ç† - é¿å…å…¼å®¹æ€§é—®é¢˜
def ensure_utf8_output():
    """ç¡®ä¿UTF-8è¾“å‡º"""
    try:
        # å°è¯•é‡æ–°é…ç½®ç¼–ç 
        if hasattr(sys.stdout, 'reconfigure'):
            sys.stdout.reconfigure(encoding='utf-8')
            sys.stderr.reconfigure(encoding='utf-8')
        elif sys.platform.startswith('win'):
            # Windowså¤‡ç”¨æ–¹æ¡ˆ
            import codecs
            if hasattr(sys.stdout, 'detach'):
                sys.stdout = codecs.getwriter('utf-8')(sys.stdout.detach())
                sys.stderr = codecs.getwriter('utf-8')(sys.stderr.detach())
    except Exception:
        # å¦‚æœæ‰€æœ‰ç¼–ç é…ç½®éƒ½å¤±è´¥ï¼Œå°±ä½¿ç”¨é»˜è®¤é…ç½®
        pass

# è°ƒç”¨ç¼–ç è®¾ç½®
ensure_utf8_output()

class GeminiService:
    def __init__(self, api_key=None, debug=False):
        """åˆå§‹åŒ–GeminiæœåŠ¡"""
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')
        self.debug = debug
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
        
        self.client = genai.Client(api_key=self.api_key)
        if self.debug:
            print(f"âœ… Python Gemini æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
    
    def analyze_video(self, video_path, prompt="Summarize this video. Then create a quiz with an answer key based on the information in this video."):
        """
        åˆ†æè§†é¢‘å†…å®¹
        
        Args:
            video_path (str): è§†é¢‘æ–‡ä»¶è·¯å¾„
            prompt (str): åˆ†ææç¤ºè¯
            
        Returns:
            dict: åˆ†æç»“æœ
        """
        try:
            import sys
            
            # ä¸Šä¼ è§†é¢‘æ–‡ä»¶
            if self.debug:
                print(f"ğŸ“ å¼€å§‹ä¸Šä¼ è§†é¢‘æ–‡ä»¶: {video_path}", file=sys.stderr)
            
            uploaded_file = self.client.files.upload(file=video_path)
            
            if self.debug:
                print(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œæ–‡ä»¶ID: {uploaded_file.name}", file=sys.stderr)
                print(f"ğŸ“Š æ–‡ä»¶çŠ¶æ€: {uploaded_file.state.name}", file=sys.stderr)
            
            # ç­‰å¾…æ–‡ä»¶å¤„ç†å®Œæˆï¼Œæœ€å¤šç­‰å¾…10åˆ†é’Ÿ
            max_wait_time = 600  # 10åˆ†é’Ÿ
            wait_time = 0
            file_info = uploaded_file
            
            while file_info.state.name != "ACTIVE" and wait_time < max_wait_time:
                if self.debug:
                    print(f"â³ å½“å‰çŠ¶æ€: {file_info.state.name} - å·²ç­‰å¾…{wait_time}ç§’", file=sys.stderr)
                
                time.sleep(5)
                wait_time += 5
                file_info = self.client.files.get(name=uploaded_file.name)
            
            if file_info.state.name != "ACTIVE":
                return {
                    'success': False,
                    'error': f'æ–‡ä»¶å¤„ç†è¶…æ—¶ï¼Œå½“å‰çŠ¶æ€: {file_info.state.name}'
                }
            
            if self.debug:
                print("âœ… æ–‡ä»¶å¤„ç†å®Œæˆï¼Œå¼€å§‹ç”Ÿæˆå†…å®¹...", file=sys.stderr)
            
            # ç”Ÿæˆå†…å®¹
            response = self.client.models.generate_content(
                model="gemini-2.0-flash",
                contents=[uploaded_file, prompt]
            )

            
            # å¤„ç†usage metadata
            usage_info = {
                'prompt_tokens': 0,
                'completion_tokens': 0,
                'total_tokens': 0
            }
            
            try:
                if hasattr(response, 'usage_metadata') and response.usage_metadata:
                    usage_info = {
                        'prompt_tokens': getattr(response.usage_metadata, 'prompt_token_count', 0),
                        'completion_tokens': getattr(response.usage_metadata, 'candidates_token_count', 0),
                        'total_tokens': getattr(response.usage_metadata, 'total_token_count', 0)
                    }
            except Exception as e:
                if self.debug:
                    print(f"âš ï¸ è·å–ä½¿ç”¨ç»Ÿè®¡å¤±è´¥: {e}")
            
            return {
                'success': True,
                'text': response.text,
                'file_id': uploaded_file.name,
                'usage': usage_info
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def generate_text(self, content, system_instruction=None, model="gemini-2.0-flash"):
        """
        ç”Ÿæˆæ–‡æœ¬å†…å®¹
        
        Args:
            content (str): è¾“å…¥å†…å®¹
            system_instruction (str): ç³»ç»ŸæŒ‡ä»¤
            model (str): ä½¿ç”¨çš„æ¨¡å‹
            
        Returns:
            dict: ç”Ÿæˆç»“æœ
        """
        try:
            
            # æ„å»ºé…ç½®
            config = {}
            if system_instruction:
                config = types.GenerateContentConfig(
                    system_instruction=system_instruction,
                )
            
            # ç”Ÿæˆå†…å®¹
            response = self.client.models.generate_content(
                model=model,
                config=config if system_instruction else None,
                contents=content
            )

            
            # å¤„ç†usage metadata
            usage_info = {
                'prompt_tokens': 0,
                'completion_tokens': 0,
                'total_tokens': 0
            }
            
            try:
                if hasattr(response, 'usage_metadata') and response.usage_metadata:
                    usage_info = {
                        'prompt_tokens': getattr(response.usage_metadata, 'prompt_token_count', 0),
                        'completion_tokens': getattr(response.usage_metadata, 'candidates_token_count', 0),
                        'total_tokens': getattr(response.usage_metadata, 'total_token_count', 0)
                    }
            except Exception as e:
                if self.debug:
                    print(f"âš ï¸ è·å–ä½¿ç”¨ç»Ÿè®¡å¤±è´¥: {e}")
            
            return {
                'success': True,
                'text': response.text,
                'usage': usage_info
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def analyze_novel(self, text_content, prompt, max_length=30000):
        """
        åˆ†æå°è¯´å†…å®¹
        
        Args:
            text_content (str): å°è¯´æ–‡æœ¬å†…å®¹
            prompt (str): åˆ†ææç¤ºè¯
            max_length (int): æœ€å¤§å¤„ç†é•¿åº¦
            
        Returns:
            dict: åˆ†æç»“æœ
        """
        try:
            
            if len(text_content) <= max_length:
                # ç›´æ¥åˆ†æ
                full_prompt = f"{prompt}\n\nå†…å®¹ï¼š{text_content}"
                return self.generate_text(full_prompt)
            else:
                # åˆ†å—å¤„ç†
                chunks = self._split_text(text_content, max_length)
                results = []
                
                for i, chunk in enumerate(chunks):
                    chunk_prompt = f"{prompt}\n\nè¿™æ˜¯æ–‡æœ¬çš„ç¬¬{i+1}éƒ¨åˆ†ï¼ˆå…±{len(chunks)}éƒ¨åˆ†ï¼‰ï¼š\n\n{chunk}"
                    result = self.generate_text(chunk_prompt)
                    
                    if result['success']:
                        results.append(result)
                    else:
                        return result  # å¦‚æœæœ‰é”™è¯¯ï¼Œç›´æ¥è¿”å›
                    
                    # é¿å…APIè°ƒç”¨è¿‡å¿«
                    if i < len(chunks) - 1:
                        time.sleep(1)
                
                # åˆå¹¶ç»“æœ
                combined_text = '\n\n'.join([f"ç¬¬{i+1}éƒ¨åˆ†åˆ†æï¼š\n{r['text']}" for i, r in enumerate(results)])
                
                return {
                    'success': True,
                    'text': combined_text,
                    'usage': {
                        'prompt_tokens': sum(r['usage']['prompt_tokens'] for r in results),
                        'completion_tokens': sum(r['usage']['completion_tokens'] for r in results),
                        'total_tokens': sum(r['usage']['total_tokens'] for r in results)
                    }
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def _split_text(self, text, max_length):
        """åˆ†å‰²é•¿æ–‡æœ¬"""
        chunks = []
        current_chunk = ''
        sentences = text.split('ã€‚')
        
        for sentence in sentences:
            if len(current_chunk) + len(sentence) > max_length:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                    current_chunk = sentence + 'ã€‚'
                else:
                    # å¦‚æœå•ä¸ªå¥å­å°±è¶…é•¿ï¼Œå¼ºåˆ¶åˆ†å‰²
                    chunks.append(sentence[:max_length])
                    current_chunk = sentence[max_length:] + 'ã€‚'
            else:
                current_chunk += sentence + 'ã€‚'
        
        if current_chunk.strip():
            chunks.append(current_chunk.strip())
        
        return chunks

def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    
    if len(sys.argv) < 2:
        print("âŒ ç”¨æ³•: python gemini_service.py <command> [args...]", file=sys.stderr)
        print("ğŸ“‹ å¯ç”¨å‘½ä»¤:", file=sys.stderr)
        print("   video <video_path> [prompt]", file=sys.stderr)
        print("   text <content> [system_instruction]", file=sys.stderr)
        print("   novel <text_content> <prompt>", file=sys.stderr)
        return
    
    # ä»ç¯å¢ƒå˜é‡æˆ–å‚æ•°è·å–APIå¯†é’¥
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        print("âŒ è¯·è®¾ç½® GEMINI_API_KEY ç¯å¢ƒå˜é‡", file=sys.stderr)
        return
    
    try:
        # é»˜è®¤éè°ƒè¯•æ¨¡å¼ï¼Œé™¤éæ˜ç¡®æŒ‡å®š
        debug_mode = "--debug" in sys.argv
        service = GeminiService(api_key, debug=debug_mode)
        command = sys.argv[1]
        
        if command == "video":
            if len(sys.argv) < 3:
                print("âŒ ç”¨æ³•: python gemini_service.py video <video_path> [prompt]")
                return
            
            video_path = sys.argv[2]
            prompt = sys.argv[3] if len(sys.argv) > 3 else "Summarize this video. Then create a quiz with an answer key based on the information in this video."
            
            result = service.analyze_video(video_path, prompt)
            print(json.dumps(result, ensure_ascii=False))
            
        elif command == "text":
            if len(sys.argv) < 3:
                print("âŒ ç”¨æ³•: python gemini_service.py text <content> [system_instruction]")
                return
            
            content = sys.argv[2]
            system_instruction = sys.argv[3] if len(sys.argv) > 3 else None
            
            result = service.generate_text(content, system_instruction)
            output = json.dumps(result, ensure_ascii=False, separators=(',', ':'))
            print(output, flush=True)
            
        elif command == "novel":
            if len(sys.argv) < 4:
                print("âŒ ç”¨æ³•: python gemini_service.py novel <text_content> <prompt>")
                return
            
            text_content = sys.argv[2]
            prompt = sys.argv[3]
            
            result = service.analyze_novel(text_content, prompt)
            print(json.dumps(result, ensure_ascii=False))
            
        else:
            print(f"âŒ æœªçŸ¥å‘½ä»¤: {command}")
            
    except Exception as e:
        error_result = {
            'success': False,
            'error': str(e)
        }
        print(json.dumps(error_result, ensure_ascii=False))

if __name__ == "__main__":
    main() 